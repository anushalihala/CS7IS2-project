{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI Project_CNN.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgg2i5ocXsGr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "388ac6a4-e5eb-438e-ebe7-d854f8bf2bca"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "from keras.layers import Dense,Flatten, Conv2D\n",
        "from keras.layers import MaxPooling2D, Dropout\n",
        "from keras.utils import np_utils, print_summary\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.callbacks import TensorBoard"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will switch to TensorFlow 2.x on the 27th of March, 2020.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now\n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkXepAO82iMJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "28ceec45-986b-4be0-e196-d163af1cc2de"
      },
      "source": [
        "files = os.listdir(\"/content/drive/My Drive/Data\")\n",
        "files"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['full_numpy_bitmap_apple.npy',\n",
              " 'full_numpy_bitmap_bowtie.npy',\n",
              " 'full_numpy_bitmap_candle.npy',\n",
              " 'full_numpy_bitmap_door.npy',\n",
              " 'full_numpy_bitmap_envelope.npy',\n",
              " 'full_numpy_bitmap_fish.npy',\n",
              " 'full_numpy_bitmap_guitar.npy',\n",
              " 'full_numpy_bitmap_ice cream.npy',\n",
              " 'full_numpy_bitmap_lightning.npy',\n",
              " 'full_numpy_bitmap_moon.npy',\n",
              " 'full_numpy_bitmap_mountain.npy',\n",
              " 'full_numpy_bitmap_star.npy',\n",
              " 'full_numpy_bitmap_tent.npy',\n",
              " 'full_numpy_bitmap_toothbrush.npy',\n",
              " 'full_numpy_bitmap_wristwatch.npy']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KK6KQOQ2n5x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = []\n",
        "x_load = []\n",
        "y = []\n",
        "y_load = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARISrIHE26hH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data():\n",
        "    count = 0\n",
        "    for file in files:\n",
        "        file = \"/content/drive/My Drive/Data/\" + file\n",
        "        x = np.load(file)\n",
        "        x = x.astype('float32') / 255.\n",
        "        x = x[0:10000, :]\n",
        "        x_load.append(x)\n",
        "        y = [count for _ in range(10000)]\n",
        "        count += 1\n",
        "        y = np.array(y).astype('float32')\n",
        "        y = y.reshape(y.shape[0], 1)\n",
        "        y_load.append(y)\n",
        "    return x_load, y_load"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eixjcB72-Pi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features, labels = load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQgd6RetF72O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 888
        },
        "outputId": "5426971c-350c-44cf-b3f6-35b7345d0d2d"
      },
      "source": [
        "features = np.array(features).astype('float32')\n",
        "features"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bdkmK5WJwVT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "34fc5048-5094-4612-b328-3f49f6c3fae2"
      },
      "source": [
        "features.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15, 10000, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmlNNFZyGH28",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 888
        },
        "outputId": "40c865be-1ee9-4530-a828-550009a73913"
      },
      "source": [
        "labels = np.array(labels).astype('float32')\n",
        "labels"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[ 0.],\n",
              "        [ 0.],\n",
              "        [ 0.],\n",
              "        ...,\n",
              "        [ 0.],\n",
              "        [ 0.],\n",
              "        [ 0.]],\n",
              "\n",
              "       [[ 1.],\n",
              "        [ 1.],\n",
              "        [ 1.],\n",
              "        ...,\n",
              "        [ 1.],\n",
              "        [ 1.],\n",
              "        [ 1.]],\n",
              "\n",
              "       [[ 2.],\n",
              "        [ 2.],\n",
              "        [ 2.],\n",
              "        ...,\n",
              "        [ 2.],\n",
              "        [ 2.],\n",
              "        [ 2.]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[12.],\n",
              "        [12.],\n",
              "        [12.],\n",
              "        ...,\n",
              "        [12.],\n",
              "        [12.],\n",
              "        [12.]],\n",
              "\n",
              "       [[13.],\n",
              "        [13.],\n",
              "        [13.],\n",
              "        ...,\n",
              "        [13.],\n",
              "        [13.],\n",
              "        [13.]],\n",
              "\n",
              "       [[14.],\n",
              "        [14.],\n",
              "        [14.],\n",
              "        ...,\n",
              "        [14.],\n",
              "        [14.],\n",
              "        [14.]]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yZu1BwLJ0TW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "33048708-e0eb-4150-d270-a6f4207dcf5c"
      },
      "source": [
        "labels.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15, 10000, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rQgMfu-KOdm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features=features.reshape(features.shape[0]*features.shape[1],features.shape[2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sGcMtYQv8I7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels=labels.reshape(labels.shape[0]*labels.shape[1],labels.shape[2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nL7yfrYwqAW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"features\", \"wb\") as f:\n",
        "    pickle.dump(features, f, protocol=4)\n",
        "with open(\"labels\", \"wb\") as f:\n",
        "    pickle.dump(labels, f, protocol=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Zaz5hDSw0Xl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def keras_model(image_x, image_y):\n",
        "    num_of_classes = 15\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, (5, 5), input_shape=(image_x,image_y,1), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
        "    model.add(Conv2D(64, (5, 5), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    model.add(Dropout(0.6))\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dropout(0.6))\n",
        "    model.add(Dense(num_of_classes, activation='softmax'))\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    filepath = \"QuickDraw.h5\"\n",
        "    checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "    callbacks_list = [checkpoint]\n",
        "\n",
        "    return model, callbacks_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fF81B-RuxfiV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loadFromPickle():\n",
        "    with open(\"features\", \"rb\") as f:\n",
        "        features = np.array(pickle.load(f))\n",
        "    with open(\"labels\", \"rb\") as f:\n",
        "        labels = np.array(pickle.load(f))\n",
        "\n",
        "    return features, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZY8xMiFlxjHx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def augmentData(features, labels):\n",
        "    features = np.append(features, features[:, :, ::-1], axis=0)\n",
        "    labels = np.append(labels, -labels, axis=0)\n",
        "    return features, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tL0piO5tx45x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepress_labels(labels):\n",
        "    labels = np_utils.to_categorical(labels)\n",
        "    return labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LukRK_owx7Y9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6a9b0a69-1df9-403d-a058-ec20704c194d"
      },
      "source": [
        "def main():\n",
        "    features, labels = loadFromPickle()\n",
        "    # features, labels = augmentData(features, labels)\n",
        "    features, labels = shuffle(features, labels)\n",
        "    labels=prepress_labels(labels)\n",
        "    train_x, test_x, train_y, test_y = train_test_split(features, labels, random_state=0,\n",
        "                                                        test_size=0.1)\n",
        "    train_x = train_x.reshape(train_x.shape[0], 28, 28, 1)\n",
        "    test_x = test_x.reshape(test_x.shape[0], 28, 28, 1)\n",
        "    model, callbacks_list = keras_model(28,28)\n",
        "    print_summary(model)\n",
        "    model.fit(train_x, train_y, validation_data=(test_x, test_y), epochs=3, batch_size=64,\n",
        "              callbacks=[TensorBoard(log_dir=\"QuickDraw\")])\n",
        "    model.save('QuickDraw.h5')\n",
        "\n",
        "main()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 24, 24, 32)        832       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 8, 8, 64)          51264     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 15)                1935      \n",
            "=================================================================\n",
            "Total params: 644,495\n",
            "Trainable params: 644,495\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 135000 samples, validate on 15000 samples\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1122: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1125: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "Epoch 1/3\n",
            "135000/135000 [==============================] - 150s 1ms/step - loss: 0.6439 - acc: 0.8156 - val_loss: 0.3188 - val_acc: 0.9098\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1265: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
            "\n",
            "Epoch 2/3\n",
            "135000/135000 [==============================] - 149s 1ms/step - loss: 0.3444 - acc: 0.9081 - val_loss: 0.2620 - val_acc: 0.9275\n",
            "Epoch 3/3\n",
            "135000/135000 [==============================] - 152s 1ms/step - loss: 0.2938 - acc: 0.9223 - val_loss: 0.2429 - val_acc: 0.9340\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LcsKNaB0ojP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "from keras.models import load_model\n",
        "import numpy as np\n",
        "from collections import deque\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CSg3j390vqV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "8558a79c-f22b-4338-ec98-fe2097d59101"
      },
      "source": [
        "model = load_model('QuickDraw.h5')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHMjyBlq00EB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3ce669df-2789-45bf-9480-badd5fdcdbb9"
      },
      "source": [
        "model"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.engine.sequential.Sequential at 0x7f12c3f6fa90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkKct9Rd01w4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def main():\n",
        "    emojis = get_QD_emojis()\n",
        "    cap = cv2.VideoCapture(0)\n",
        "    Lower_green = np.array([110, 50, 50])\n",
        "    Upper_green = np.array([130, 255, 255])\n",
        "    pts = deque(maxlen=512)\n",
        "    blackboard = np.zeros((480, 640, 3), dtype=np.uint8)\n",
        "    digit = np.zeros((200, 200, 3), dtype=np.uint8)\n",
        "    pred_class = 0\n",
        "\n",
        "    while (cap.isOpened()):\n",
        "        ret, img = cap.read()\n",
        "        img = cv2.flip(img, 1)\n",
        "        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
        "        kernel = np.ones((5, 5), np.uint8)\n",
        "        mask = cv2.inRange(hsv, Lower_green, Upper_green)\n",
        "        mask = cv2.erode(mask, kernel, iterations=2)\n",
        "        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
        "        # mask=cv2.morphologyEx(mask,cv2.MORPH_CLOSE,kernel)\n",
        "        mask = cv2.dilate(mask, kernel, iterations=1)\n",
        "        res = cv2.bitwise_and(img, img, mask=mask)\n",
        "        cnts, heir = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[-2:]\n",
        "        center = None\n",
        "\n",
        "        if len(cnts) >= 1:\n",
        "            cnt = max(cnts, key=cv2.contourArea)\n",
        "            if cv2.contourArea(cnt) > 200:\n",
        "                ((x, y), radius) = cv2.minEnclosingCircle(cnt)\n",
        "                cv2.circle(img, (int(x), int(y)), int(radius), (0, 255, 255), 2)\n",
        "                cv2.circle(img, center, 5, (0, 0, 255), -1)\n",
        "                M = cv2.moments(cnt)\n",
        "                center = (int(M['m10'] / M['m00']), int(M['m01'] / M['m00']))\n",
        "                pts.appendleft(center)\n",
        "                for i in range(1, len(pts)):\n",
        "                    if pts[i - 1] is None or pts[i] is None:\n",
        "                        continue\n",
        "                    cv2.line(blackboard, pts[i - 1], pts[i], (255, 255, 255), 7)\n",
        "                    cv2.line(img, pts[i - 1], pts[i], (0, 0, 255), 2)\n",
        "        elif len(cnts) == 0:\n",
        "            if len(pts) != []:\n",
        "                blackboard_gray = cv2.cvtColor(blackboard, cv2.COLOR_BGR2GRAY)\n",
        "                blur1 = cv2.medianBlur(blackboard_gray, 15)\n",
        "                blur1 = cv2.GaussianBlur(blur1, (5, 5), 0)\n",
        "                thresh1 = cv2.threshold(blur1, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
        "                blackboard_cnts = cv2.findContours(thresh1.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)[1]\n",
        "                if len(blackboard_cnts) >= 1:\n",
        "                    cnt = max(blackboard_cnts, key=cv2.contourArea)\n",
        "                    print(cv2.contourArea(cnt))\n",
        "                    if cv2.contourArea(cnt) > 2000:\n",
        "                        x, y, w, h = cv2.boundingRect(cnt)\n",
        "                        digit = blackboard_gray[y:y + h, x:x + w]\n",
        "                        pred_probab, pred_class = keras_predict(model, digit)\n",
        "                        print(pred_class, pred_probab)\n",
        "\n",
        "            pts = deque(maxlen=512)\n",
        "            blackboard = np.zeros((480, 640, 3), dtype=np.uint8)\n",
        "            img = overlay(img, emojis[pred_class], 400, 250, 100, 100)\n",
        "        cv2.imshow(\"Frame\", img)\n",
        "        k = cv2.waitKey(10)\n",
        "        if k == 27:\n",
        "            break\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7477DS10_YU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def keras_predict(model, image):\n",
        "    processed = keras_process_image(image)\n",
        "    print(\"processed: \" + str(processed.shape))\n",
        "    pred_probab = model.predict(processed)[0]\n",
        "    pred_class = list(pred_probab).index(max(pred_probab))\n",
        "    return max(pred_probab), pred_class"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbHZnp-t1EwI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def keras_process_image(img):\n",
        "    image_x = 28\n",
        "    image_y = 28\n",
        "    img = cv2.resize(img, (image_x, image_y))\n",
        "    img = np.array(img, dtype=np.float32)\n",
        "    img = np.reshape(img, (-1, image_x, image_y, 1))\n",
        "    return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kkr2M5eL1Ht8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_QD_emojis():\n",
        "    emojis_folder = '/content/Emojis'\n",
        "    emojis = []\n",
        "    for emoji in range(len(os.listdir(emojis_folder))):\n",
        "        print(emoji)\n",
        "        emojis.append(cv2.imread(emojis_folder + str(emoji) + '.png', -1))\n",
        "    return emojis"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8P7Si5Z1I0q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def overlay(image, emoji, x, y, w, h):\n",
        "    emoji = cv2.resize(emoji, (w, h))\n",
        "    try:\n",
        "        image[y:y + h, x:x + w] = blend_transparent(image[y:y + h, x:x + w], emoji)\n",
        "    except:\n",
        "        pass\n",
        "    return image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6TxnkrZ1Kxh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def blend_transparent(face_img, overlay_t_img):\n",
        "    # Split out the transparency mask from the colour info\n",
        "    overlay_img = overlay_t_img[:, :, :3]  # Grab the BRG planes\n",
        "    overlay_mask = overlay_t_img[:, :, 3:]  # And the alpha plane\n",
        "\n",
        "    # Again calculate the inverse mask\n",
        "    background_mask = 255 - overlay_mask\n",
        "\n",
        "    # Turn the masks into three channel, so we can use them as weights\n",
        "    overlay_mask = cv2.cvtColor(overlay_mask, cv2.COLOR_GRAY2BGR)\n",
        "    background_mask = cv2.cvtColor(background_mask, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "    # Create a masked out face image, and masked out overlay\n",
        "    # We convert the images to floating point in range 0.0 - 1.0\n",
        "    face_part = (face_img * (1 / 255.0)) * (background_mask * (1 / 255.0))\n",
        "    overlay_part = (overlay_img * (1 / 255.0)) * (overlay_mask * (1 / 255.0))\n",
        "\n",
        "    # And finally just add them together, and rescale it back to an 8bit integer image\n",
        "    return np.uint8(cv2.addWeighted(face_part, 255.0, overlay_part, 255.0, 0.0))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHmIBXGE1NDq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1fc8721e-cb30-42b0-b33c-40ad553ec530"
      },
      "source": [
        "keras_predict(model, np.zeros((50, 50, 1), dtype=np.uint8))\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "processed: (1, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}